import os
import json
import shutil
from pathlib import Path
from tqdm import tqdm
import re

def sanitize_folder_name(name):
    """í´ë”ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ ì œê±°í•˜ê³  ì •ë¦¬"""
    if not name or name.strip() == "":
        return "ê¸°íƒ€"
    
    # Windowsì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë“¤ì„ ì œê±°
    invalid_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
    for char in invalid_chars:
        name = name.replace(char, '_')
    
    return name.strip()

def analyze_legal_topic(json_data):
    """JSON ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë²•ì  ì£¼ì œë¥¼ ê²°ì •"""
    
    # ë¶„ì„í•  í•„ë“œë“¤
    ì‚¬ê±´ëª… = json_data.get('ì‚¬ê±´ëª…', '')
    íŒì‹œì‚¬í•­ = json_data.get('íŒì‹œì‚¬í•­', '')
    íŒê²°ìš”ì§€ = json_data.get('íŒê²°ìš”ì§€', '')
    ì°¸ì¡°ì¡°ë¬¸ = json_data.get('ì°¸ì¡°ì¡°ë¬¸', '')
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ë¶„ì„
    combined_text = f"{ì‚¬ê±´ëª…} {íŒì‹œì‚¬í•­} {íŒê²°ìš”ì§€} {ì°¸ì¡°ì¡°ë¬¸}".lower()
    
    # ë²•ì  ì£¼ì œ ë¶„ë¥˜ ê·œì¹™ (ìš°ì„ ìˆœìœ„ ìˆœ)
    topic_rules = [
        # ë³´ì¦ê¸ˆ ê´€ë ¨
        {
            'keywords': ['ë³´ì¦ê¸ˆë°˜í™˜', 'ë³´ì¦ê¸ˆ', 'ì „ì„¸ê¸ˆ', 'ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ', 'ì „ì„¸ë³´ì¦ê¸ˆ'],
            'topic': 'ë³´ì¦ê¸ˆë°˜í™˜'
        },
        # ëª…ë„ ê´€ë ¨
        {
            'keywords': ['ëª…ë„', 'ê±´ë¬¼ì¸ë„', 'í† ì§€ì¸ë„', 'í‡´ê±°', 'ì ìœ íšŒë³µ'],
            'topic': 'ëª…ë„ì†Œì†¡'
        },
        # ì„ëŒ€ë£Œ ê´€ë ¨
        {
            'keywords': ['ì„ëŒ€ë£Œ', 'ì°¨ì„', 'ì›”ì„¸', 'ì„ë£Œ', 'ì°¨ì„ì¦ì•¡', 'ì„ëŒ€ë£Œì¦ì•¡'],
            'topic': 'ì„ëŒ€ë£Œë¶„ìŸ'
        },
        # ê³„ì•½ ê´€ë ¨
        {
            'keywords': ['ì„ëŒ€ì°¨ê³„ì•½', 'ê³„ì•½í•´ì§€', 'ê³„ì•½í•´ì œ', 'ê³„ì•½ê°±ì‹ ', 'ê³„ì•½ì—°ì¥'],
            'topic': 'ì„ëŒ€ì°¨ê³„ì•½'
        },
        # ìš°ì„ ë³€ì œê¶Œ ê´€ë ¨
        {
            'keywords': ['ìš°ì„ ë³€ì œ', 'ëŒ€í•­ë ¥', 'ë°°ë‹¹', 'ê²½ë§¤', 'ìš°ì„ ë³€ì œê¶Œ'],
            'topic': 'ìš°ì„ ë³€ì œê¶Œ'
        },
        # ì†í•´ë°°ìƒ ê´€ë ¨
        {
            'keywords': ['ì†í•´ë°°ìƒ', 'ì†í•´', 'ë°°ìƒ', 'ìœ„ì•½ê¸ˆ', 'ì§€ì—°ì†í•´ê¸ˆ'],
            'topic': 'ì†í•´ë°°ìƒ'
        },
        # ìƒê°€ì„ëŒ€ì°¨ ê´€ë ¨
        {
            'keywords': ['ìƒê°€ê±´ë¬¼', 'ìƒê°€ì„ëŒ€ì°¨', 'ê¶Œë¦¬ê¸ˆ', 'ì˜ì—…ê¶Œ', 'ìƒê°€ê±´ë¬¼ì„ëŒ€ì°¨ë³´í˜¸ë²•'],
            'topic': 'ìƒê°€ì„ëŒ€ì°¨'
        },
        # ì£¼íƒì„ëŒ€ì°¨ ê´€ë ¨
        {
            'keywords': ['ì£¼íƒì„ëŒ€ì°¨', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•', 'ì „ì›”ì„¸', 'ì£¼ê±°ìš©'],
            'topic': 'ì£¼íƒì„ëŒ€ì°¨'
        },
        # ë¶€ë™ì‚° ë“±ê¸° ê´€ë ¨
        {
            'keywords': ['ì†Œìœ ê¶Œì´ì „ë“±ê¸°', 'ë“±ê¸°', 'ì†Œìœ ê¶Œ', 'ë“±ê¸°ë§ì†Œ', 'ê°€ë“±ê¸°'],
            'topic': 'ë¶€ë™ì‚°ë“±ê¸°'
        },
        # ì‚¬í•´í–‰ìœ„ ê´€ë ¨
        {
            'keywords': ['ì‚¬í•´í–‰ìœ„', 'ì‚¬í•´í–‰ìœ„ì·¨ì†Œ', 'ì±„ê¶Œìì·¨ì†Œê¶Œ'],
            'topic': 'ì‚¬í•´í–‰ìœ„ì·¨ì†Œ'
        }
    ]
    
    # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜
    for rule in topic_rules:
        for keyword in rule['keywords']:
            if keyword in combined_text:
                return rule['topic']
    
    # ì‚¬ê±´ëª… ê¸°ë°˜ ì¶”ê°€ ë¶„ë¥˜
    if 'ë°°ë‹¹ì´ì˜' in ì‚¬ê±´ëª…:
        return 'ë°°ë‹¹ì´ì˜'
    elif 'ë¶€ë‹¹ì´ë“' in ì‚¬ê±´ëª…:
        return 'ë¶€ë‹¹ì´ë“ë°˜í™˜'
    elif 'ëŒ€ì—¬ê¸ˆ' in ì‚¬ê±´ëª…:
        return 'ëŒ€ì—¬ê¸ˆë°˜í™˜'
    elif 'ë§¤ë§¤' in ì‚¬ê±´ëª…:
        return 'ë§¤ë§¤ê³„ì•½'
    
    # ê¸°ë³¸ ë¶„ë¥˜
    return 'ê¸°íƒ€'

def group_by_legal_topics():
    """2015ë…„ ì´í›„ ë°ì´í„°ë¥¼ ë²•ì  ì£¼ì œë³„ë¡œ ê·¸ë£¹í™”"""
    
    source_dir = Path("./grouped_data")
    if not source_dir.exists():
        print("âŒ grouped_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    output_dir = Path("./topic_grouped_data")
    output_dir.mkdir(exist_ok=True)
    
    # 2015ë…„ ì´í›„ JSON íŒŒì¼ ìˆ˜ì§‘
    json_files = []
    year_stats = {}
    
    print("ğŸ” 2015ë…„ ì´í›„ íŒŒì¼ ìˆ˜ì§‘ ì¤‘...")
    
    for case_type_dir in source_dir.iterdir():
        if not case_type_dir.is_dir():
            continue
            
        for year_dir in case_type_dir.iterdir():
            if not year_dir.is_dir():
                continue
                
            year = year_dir.name
            try:
                year_int = int(year)
                if year_int >= 2015:  # 2015ë…„ ì´í›„ë§Œ
                    if year not in year_stats:
                        year_stats[year] = 0
                    
                    for json_file in year_dir.glob("*.json"):
                        json_files.append(json_file)
                        year_stats[year] += 1
            except ValueError:
                continue
    
    if not json_files:
        print("âŒ 2015ë…„ ì´í›„ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì—°ë„ë³„ í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š 2015ë…„ ì´í›„ ë°ì´í„° í˜„í™©:")
    total_files = 0
    for year in sorted(year_stats.keys()):
        count = year_stats[year]
        total_files += count
        print(f"  ğŸ“… {year}ë…„: {count:,}ê°œ")
    
    print(f"  ğŸ¯ ì´ íŒŒì¼ ìˆ˜: {total_files:,}ê°œ (ì´ {len(year_stats)}ê°œ ë…„ë„)")
    
    # ì£¼ì œë³„ íŒŒì¼ ë¶„ë¥˜
    topic_groups = {}
    
    print(f"\nğŸ” ë²•ì  ì£¼ì œ ë¶„ì„ ì¤‘...")
    with tqdm(total=len(json_files), desc="ğŸ“‹ ì£¼ì œ ë¶„ì„", unit="íŒŒì¼") as pbar:
        for file_path in json_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                topic = analyze_legal_topic(data)
                
                if topic not in topic_groups:
                    topic_groups[topic] = []
                
                topic_groups[topic].append(file_path)
                
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                pbar.set_postfix({'í˜„ì¬ì£¼ì œ': topic, 'ë¶„ë¥˜ë¨': len(topic_groups)})
                pbar.update(1)
                
            except Exception as e:
                pbar.write(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path}): {e}")
                pbar.update(1)
    
    print(f"\nğŸ“‹ ë°œê²¬ëœ ë²•ì  ì£¼ì œ: {len(topic_groups)}ê°œ")
    
    # ì£¼ì œë³„ í†µê³„ í‘œì‹œ (íŒŒì¼ ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
    sorted_topics = sorted(topic_groups.items(), key=lambda x: len(x[1]), reverse=True)
    for topic, files in sorted_topics:
        print(f"  ğŸ“‚ {topic}: {len(files):,}ê°œ")
    
    # ì£¼ì œë³„ í´ë” ìƒì„± ë° íŒŒì¼ ë³µì‚¬
    print("\nğŸ“ ì£¼ì œë³„ í´ë” ìƒì„± ë° íŒŒì¼ ë³µì‚¬ ì¤‘...")
    
    copied_count = 0
    
    with tqdm(total=len(json_files), desc="ğŸ“¦ íŒŒì¼ ë³µì‚¬", unit="íŒŒì¼") as main_pbar:
        for topic, files in topic_groups.items():
            # ì£¼ì œë³„ í´ë” ìƒì„±
            topic_dir = output_dir / sanitize_folder_name(topic)
            topic_dir.mkdir(exist_ok=True)
            
            # íŒŒì¼ ë³µì‚¬
            for file_path in files:
                try:
                    target_file = topic_dir / file_path.name
                    
                    # ê°™ì€ ì´ë¦„ì˜ íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                    if target_file.exists():
                        target_file.unlink()
                    
                    shutil.copy2(str(file_path), str(target_file))
                    copied_count += 1
                    
                    # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                    main_pbar.set_postfix({
                        'í˜„ì¬ì£¼ì œ': topic,
                        'ì™„ë£Œ': copied_count
                    })
                    main_pbar.update(1)
                    
                except Exception as e:
                    main_pbar.write(f"âŒ íŒŒì¼ ë³µì‚¬ ì˜¤ë¥˜ ({file_path}): {e}")
                    main_pbar.update(1)
    
    print(f"\nâœ… ë²•ì  ì£¼ì œë³„ ê·¸ë£¹í™” ì™„ë£Œ! ì´ {copied_count:,}ê°œ íŒŒì¼ ë³µì‚¬")
    
    # ìµœì¢… ê²°ê³¼ ìƒì„¸ ì¶œë ¥
    print("\n" + "="*70)
    print("ğŸ“Š ìµœì¢… ë²•ì  ì£¼ì œë³„ ê·¸ë£¹í™” ê²°ê³¼ (2015ë…„~í˜„ì¬)")
    print("="*70)
    
    total_result_files = 0
    
    for i, (topic, files) in enumerate(sorted_topics, 1):
        file_count = len(files)
        total_result_files += file_count
        percentage = (file_count / total_files * 100) if total_files > 0 else 0
        
        print(f"{i:2d}. ğŸ“ {topic}: {file_count:,}ê°œ ({percentage:.1f}%)")
        
        # ê° ì£¼ì œë³„ ì—°ë„ ë¶„í¬ ë¶„ì„
        year_distribution = {}
        for file_path in files:
            # íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ
            year_match = re.search(r'_(\d{4})_', file_path.name)
            if year_match:
                year = year_match.group(1)
                if year not in year_distribution:
                    year_distribution[year] = 0
                year_distribution[year] += 1
        
        # ì—°ë„ë³„ ë¶„í¬ í‘œì‹œ (ìƒìœ„ 5ê°œë…„ë„ë§Œ)
        if year_distribution:
            sorted_years = sorted(year_distribution.items(), key=lambda x: x[1], reverse=True)[:5]
            year_info = []
            for year, count in sorted_years:
                year_info.append(f"{year}ë…„({count}ê°œ)")
            remaining_years = len(year_distribution) - len(sorted_years)
            if remaining_years > 0:
                year_info.append(f"ì™¸ {remaining_years}ê°œë…„ë„")
            print(f"     â””â”€ ì£¼ìš” ì—°ë„: {', '.join(year_info)}")
    
    print("\n" + "-"*70)
    print(f"ğŸ¯ ì´ ë¶„ì„ íŒŒì¼: {total_files:,}ê°œ")
    print(f"ğŸ“‚ ì´ ë²•ì  ì£¼ì œ: {len(topic_groups)}ê°œ")
    print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: 2015ë…„~í˜„ì¬ ({len(year_stats)}ê°œ ë…„ë„)")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: ./topic_grouped_data/")
    
    # ì—°ë„ë³„ ìƒì„¸ í†µê³„ (ìƒëµ ì—†ì´ ëª¨ë“  ì—°ë„ í‘œì‹œ)
    print(f"\nğŸ“… ì—°ë„ë³„ ìƒì„¸ í†µê³„:")
    for year in sorted(year_stats.keys()):
        count = year_stats[year]
        percentage = (count / total_files * 100) if total_files > 0 else 0
        print(f"  ğŸ“… {year}ë…„: {count:,}ê°œ ({percentage:.1f}%)")

if __name__ == "__main__":
    print("ğŸš€ 2015ë…„ ì´í›„ ë°ì´í„° ë²•ì  ì£¼ì œë³„ ê·¸ë£¹í™” ì‹œì‘")
    print("=" * 70)
    group_by_legal_topics()
